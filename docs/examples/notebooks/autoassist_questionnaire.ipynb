{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auto-fill Questionnaire using Chain of Thought or Few-Shot Examples\n",
    "\n",
    "This notebook showcases the application of few-shot examples in autofilling questionnaires. It utilizes a json file (`risk_questionnaire_cot.json`) to\n",
    "provide the LLM with example responses for some use-cases.\n",
    "\n",
    "By leveraging these few-shot examples, we can enable seamless completion of lengthy questionnaires, minimizing manual effort and improving overall efficiency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seshu/Documents/2025/risk-atlas-nexus/src/risk_atlas_nexus/toolkit/job_utils.py:4: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from risk_atlas_nexus.blocks.inference import (\n",
    "    RITSInferenceEngine,\n",
    "    WMLInferenceEngine,\n",
    "    OllamaInferenceEngine,\n",
    "    VLLMInferenceEngine,\n",
    ")\n",
    "from risk_atlas_nexus.blocks.inference.params import (\n",
    "    InferenceEngineCredentials,\n",
    "    RITSInferenceEngineParams,\n",
    "    WMLInferenceEngineParams,\n",
    "    OllamaInferenceEngineParams,\n",
    "    VLLMInferenceEngineParams,\n",
    ")\n",
    "\n",
    "from risk_atlas_nexus.data import load_resource\n",
    "from risk_atlas_nexus.library import RiskAtlasNexus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Risk Atlas Nexus uses Large Language Models (LLMs) to infer risks dimensions. Therefore requires access to LLMs to inference or call the model.\n",
    "\n",
    "**Available Inference Engines**: WML, Ollama, vLLM, RITS. Please follow the [Inference APIs](https://github.com/IBM/risk-atlas-nexus?tab=readme-ov-file#install-for-inference-apis) guide before going ahead.\n",
    "\n",
    "_Note:_ RITS is intended solely for internal IBM use and requires TUNNELALL VPN for access.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-09-10 07:48:03:128] - INFO - RiskAtlasNexus - OLLAMA inference engine will execute requests on the server at http://localhost:11434.\n",
      "[2025-09-10 07:48:03:157] - INFO - RiskAtlasNexus - Created OLLAMA inference engine.\n"
     ]
    }
   ],
   "source": [
    "inference_engine = OllamaInferenceEngine(\n",
    "    model_name_or_path=\"granite3.2:8b\",\n",
    "    credentials=InferenceEngineCredentials(api_url=\"http://localhost:11434\"),\n",
    "    parameters=OllamaInferenceEngineParams(\n",
    "        num_predict=1000, temperature=0, repeat_penalty=1, num_ctx=8192\n",
    "    ),\n",
    ")\n",
    "\n",
    "# inference_engine = WMLInferenceEngine(\n",
    "#     model_name_or_path=\"ibm/granite-20b-code-instruct\",\n",
    "#     credentials={\n",
    "#         \"api_key\": \"WML_API_KEY\",\n",
    "#         \"api_url\": \"WML_API_URL\",\n",
    "#         \"project_id\": \"WML_PROJECT_ID\",\n",
    "#     },\n",
    "#     parameters=WMLInferenceEngineParams(\n",
    "#         max_new_tokens=1000, decoding_method=\"greedy\", repetition_penalty=1\n",
    "#     ),\n",
    "# )\n",
    "\n",
    "# inference_engine = VLLMInferenceEngine(\n",
    "#     model_name_or_path=\"ibm-granite/granite-3.1-8b-instruct\",\n",
    "#     credentials=InferenceEngineCredentials(\n",
    "#         api_url=\"VLLM_API_URL\", api_key=\"VLLM_API_KEY\"\n",
    "#     ),\n",
    "#     parameters=VLLMInferenceEngineParams(max_tokens=1000, temperature=0.7),\n",
    "# )\n",
    "\n",
    "# inference_engine = RITSInferenceEngine(\n",
    "#     model_name_or_path=\"ibm-granite/granite-3.1-8b-instruct\",\n",
    "#     credentials={\n",
    "#         \"api_key\": \"RITS_API_KEY\",\n",
    "#         \"api_url\": \"RITS_API_URL\",\n",
    "#     },\n",
    "#     parameters=RITSInferenceEngineParams(max_tokens=1000, temperature=0.7),\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create an instance of RiskAtlasNexus\n",
    "\n",
    "_Note: (Optional)_ You can specify your own directory in `RiskAtlasNexus(base_dir=<PATH>)` to utilize custom AI ontologies. If left blank, the system will use the provided AI ontologies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-09-10 07:48:03:379] - INFO - RiskAtlasNexus - Created RiskAtlasNexus instance. Base_dir: None\n"
     ]
    }
   ],
   "source": [
    "risk_atlas_nexus = RiskAtlasNexus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Examples for Auto-Assist Functionality\n",
    "\n",
    "The auto-assist feature utilizes few-shot examples defined in the file `risk_atlas_nexus/data/templates/risk_questionnaire_cot.json` to predict the output of the risk questionnaire.\n",
    "\n",
    "**Customization:**\n",
    "\n",
    "To adapt this auto-assist functionality to custom risk questionnaire, users need to provide their own set of questions, example intents, and corresponding answers in a json file such as in [risk_questionnaire_cot.json](https://github.com/IBM/risk-atlas-nexus/blob/main/src/risk_atlas_nexus/data/templates/risk_questionnaire_cot.json). This will enable the LLM to learn from these few-shot examples and generate responses for unseen queries.\n",
    "\n",
    "**CoT Template - Zero Shot method**\n",
    "\n",
    "Each question is accompanied by corresponding examples provided as an empty list.\n",
    "\n",
    "```shell\n",
    "  [\n",
    "      {\n",
    "          \"question\": \"In which environment is the system used?\",\n",
    "          \"cot_examples\": []\n",
    "      }\n",
    "      ...\n",
    "  ]\n",
    "```\n",
    "\n",
    "**CoT Template - Few Shot method**\n",
    "\n",
    "Each question is associated with a list of examples, each containing intent, answer, and optional explanation.\n",
    "\n",
    "```shell\n",
    "  [\n",
    "      {\n",
    "          \"question\": \"In which environment is the system used?\",\n",
    "          \"cot_examples\": [\n",
    "            {\n",
    "              \"intent\": \"Find patterns in healthcare insurance claims\",\n",
    "              \"answer\": \"Insurance Claims Processing or Risk Management or Data Analytics\",\n",
    "              \"explanation\": \"The system might be used by an insurance company's claims processing department to analyze and identify patterns in healthcare insurance claims.\"\n",
    "            },\n",
    "            {\n",
    "                \"intent\": \"optimize supply chain management in Investment banks\",\n",
    "                \"answer\": \"Treasury Departments or Asset Management Divisions or Private Banking Units\",\n",
    "                \"explanation\": null\n",
    "            },\n",
    "            ...\n",
    "          ]\n",
    "      }\n",
    "      ...\n",
    "  ]\n",
    "```\n",
    "\n",
    "In this notebook, we're using a simplified template to cover 7 questions\n",
    "from the Airo questionnaire:\n",
    "\n",
    "1. AI Domain\n",
    "2. System environment\n",
    "3. Utilized techniques\n",
    "4. Intended User\n",
    "5. Intended Purpose\n",
    "6. System Application\n",
    "7. AI Subject\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Risk Questionnaire\n",
    "\n",
    "**Note:** The cell below loads examples of risk questionnaires from Risk Atlas Master. To load your custom questionnaire, create it according to the specified format and load it instead.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'no': 'Q1',\n",
       " 'question': 'What domain does your use request fall under? Customer service/support, Technical, Information retrieval, Strategy, Code/software engineering, Communications, IT/business automation, Writing assistant, Financial, Talent and Organization including HR, Product, Marketing, Cybersecurity, Healthcare, User Research, Sales, Risk and Compliance, Design, Other',\n",
       " 'cot_examples': [{'intent': 'Optimize supply chain management in Investment banks',\n",
       "   'answer': 'Strategy',\n",
       "   'confidence': 'Likely answer from the intent',\n",
       "   'explanation': 'Since the task is involved in improving the processes to ensure better performance. It is not finance since the task is on supply chain optimization and not on financial aspects even though the application domain is banks.'},\n",
       "  {'intent': 'Ability to create dialog flows and integrations from natural language instructions.',\n",
       "   'answer': 'Customer service/support',\n",
       "   'confidence': 'Likely answer from the intent',\n",
       "   'explanation': 'Since the task relates to human conversations or generating human converstations or support.'},\n",
       "  {'intent': 'Check if a document has grammatical mistakes.',\n",
       "   'answer': 'Writing assitant',\n",
       "   'confidence': 'Likely answer from the intent',\n",
       "   'explanation': 'Since this helps in improving the quality of text. It is not customer service since this on on the quality of text rather than helping in human conversations.'},\n",
       "  {'intent': 'Optimize supply chain management in Investment banks',\n",
       "   'answer': 'Strategy',\n",
       "   'confidence': 'Likely answer from the intent',\n",
       "   'explanation': 'Since the task is involved in improving the processes to ensure better performance. It is not finance since the task is on supply chain optimization and not on financial aspects even though the application domain is banks.'},\n",
       "  {'intent': \"In the context of drug repurposing, generative AI can be employed to analyze vast databases of existing drugs and their clinical trials data. By identifying patterns and similarities, the AI can suggest potential new therapeutic indications for existing drugs, based on the chemical structure and pharmacological properties of the APIs. This process can help streamline the drug development pipeline, as it would reduce the need for time-consuming and expensive clinical trials for new indications. For instance, a drug like Atorvastatin, which is currently used to lower cholesterol, could be repurposed for the treatment of diabetic nephropathy, a kidney disease, based on the AI's analysis of similar drugs and their clinical data. This would not only save resources but also provide new treatment options for patients suffering from this debilitating condition. \",\n",
       "   'answer': 'Healthcare and strategy',\n",
       "   'confidence': 'Directly from the  input text',\n",
       "   'explanation': 'Since the task is related to healthcare and drug repurposing, which involves analyzing data related to drugs and their clinical trials, this falls under the healthcare domain. It also involves Strategy it talks about using patterns to create new treatment options.'}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk_questionnaire = load_resource(\"risk_questionnaire_cot.json\")\n",
    "\n",
    "risk_questionnaire[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways to use the inference engine to get the LLM outputs. `generate_zero_shot_risk_questionnaire_output` which gives the zero-shot output for the question and `generate_few_shot_risk_questionnaire_output` which gives the output using few-shot examples defined above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auto Assist Questionnaire - Zero Shot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferring with OLLAMA: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:54<00:00,  7.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1: What domain does your use request fall under? Customer service/support, Technical, Information retrieval, Strategy, Code/software engineering, Communications, IT/business automation, Writing assistant, Financial, Talent and Organization including HR, Product, Marketing, Cybersecurity, Healthcare, User Research, Sales, Risk and Compliance, Design, Other\n",
      "A: Customer service/support\n",
      "\n",
      "2: In which environment is the system used?\n",
      "A: The system is used in a digital environment, specifically as an AI assistant providing responses to user queries.\n",
      "\n",
      "3: What techniques are utilised in the system? Multi-modal: {Document Question/Answering, Image and text to text, Video and text to text, visual question answering}, Natural language processing: {feature extraction, fill mask, question answering, sentence similarity, summarization, table question answering, text classification, text generation, token classification, translation, zero shot classification}, computer vision: {image classification, image segmentation, text to image, object detection}, audio:{audio classification, audio to audio, text to speech}, tabular: {tabular classification, tabular regression}, reinforcement learning\n",
      "A: The system employs a variety of techniques including multi-modal capabilities such as Document Question/Answering, Image and text to text, Video and text to text, and visual question answering. In the realm of Natural Language Processing, it utilizes methods like feature extraction, fill mask, question answering, sentence similarity, summarization, table question answering, text classification, text generation, token classification, translation, and zero shot classification. For computer vision, it incorporates image classification, image segmentation, text to image, and object detection. In the audio domain, it uses audio classification, audio to audio, and text to speech. Additionally, it includes tabular methods like tabular classification and tabular regression. Lastly, it incorporates reinforcement learning techniques.\n",
      "\n",
      "4: Who is the intended user of the system?\n",
      "A: The intended user of the system is the customer service agent.\n",
      "\n",
      "5: What is the intended purpose of the system?\n",
      "A: The intended purpose of the system is to assist as a compliance officer, providing personalized, relevant responses, recommendations, and summaries of claims to support agents in their interactions with customers. This is inferred from the Intent, which specifies generating personalized content to enhance customer interactions.\n",
      "\n",
      "6: What is the application of the system?\n",
      "A: The application of the system is not explicitly provided in the given prompt. Therefore, I cannot generate a personalized, relevant response regarding its application.\n",
      "\n",
      "7: Who is the subject as per the intent?\n",
      "A: The subject in this context is the compliance officer role.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "usecase = \"Generate personalized, relevant responses, recommendations, and summaries of claims for customers to support agents to enhance their interactions with customers. Include whether the information is in the prompt, a plausible answer or not able to answer based on the prompt.\"\n",
    "\n",
    "results = risk_atlas_nexus.generate_zero_shot_risk_questionnaire_output(\n",
    "    usecase, risk_questionnaire, inference_engine\n",
    ")\n",
    "\n",
    "# Display Results\n",
    "for index, (question_data, result) in enumerate(\n",
    "    zip(risk_questionnaire, results), start=1\n",
    "):\n",
    "    print(\n",
    "        f\"\\n{index}: \"\n",
    "        + question_data[\"question\"]\n",
    "        + \"\\nA: \"\n",
    "        + result.prediction[\"answer\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, (question_data, result) in enumerate(\n",
    "#     zip(risk_questionnaire, results), start=1\n",
    "# ):\n",
    "#     print(\n",
    "#         f\"\\n{index}: \"\n",
    "#         + question_data[\"question\"]\n",
    "#         + \"\\nA: \"\n",
    "#         + result.prediction[\"answer\"]\n",
    "#         + \"\\nC: \"\n",
    "#         + result.prediction[\"Confidence\"]\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auto Assist Questionnaire - Few Shot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "usecases = load_resource(\"questionnaire_benchmark.json\")\n",
    "\n",
    "predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_map = {0: \"UseCase\", 1: \"Domain\", 2: \"Environment\", 3: \"Techniques_Utilised\", 4: \"Intended_User\", 5: \"Purpose\", 6: \"Application\", 7: \"Subject\" }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferring with OLLAMA: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [01:31<00:00, 13.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1: What domain does your use request fall under? Customer service/support, Technical, Information retrieval, Strategy, Code/software engineering, Communications, IT/business automation, Writing assistant, Financial, Talent and Organization including HR, Product, Marketing, Cybersecurity, Healthcare, User Research, Sales, Risk and Compliance, Design, Other\n",
      "A: Marketing\n",
      "C: Likely answer from the intent\n",
      "TextGenerationInferenceOutput(prediction={'answer': 'Marketing', 'explanation': 'Since the task involves analyzing social media data to understand public sentiment, which is a key aspect of marketing strategies and customer understanding.', 'confidence': 'Likely answer from the intent'}, input_tokens=None, output_tokens=None, stop_reason=None, seed=None, input_text=None, model_name_or_path='granite3.2:8b', inference_engine='OLLAMA')\n",
      "\n",
      "2: In which environment is the system used?\n",
      "A: Social Media Monitoring Teams or Public Relations Departments or Customer Service Teams\n",
      "C: Likely answer from the intent\n",
      "TextGenerationInferenceOutput(prediction={'answer': 'Social Media Monitoring Teams or Public Relations Departments or Customer Service Teams', 'explanation': '1. Social Media Monitoring Teams: Companies or organizations with dedicated social media monitoring teams could use this system to analyze public sentiment towards their brand, products, or services. 2. Public Relations Departments: PR departments might utilize this application to track and respond to public sentiment, manage crises, and develop effective communication strategies. 3. Customer Service Teams: Customer service teams could benefit from using this system to understand customer feedback, improve service quality, and address concerns proactively.', 'confidence': 'Likely answer from the intent'}, input_tokens=None, output_tokens=None, stop_reason=None, seed=None, input_text=None, model_name_or_path='granite3.2:8b', inference_engine='OLLAMA')\n",
      "\n",
      "3: What techniques are utilised in the system? Multi-modal: {Document Question/Answering, Image and text to text, Video and text to text, visual question answering}, Natural language processing: {feature extraction, fill mask, question answering, sentence similarity, summarization, table question answering, text classification, text generation, token classification, translation, zero shot classification}, computer vision: {image classification, image segmentation, text to image, object detection}, audio:{audio classification, audio to audio, text to speech}, tabular: {tabular classification, tabular regression}, reinforcement learning\n",
      "A: Natural language processing: text classification, sentiment analysis\n",
      "C: Likely answer from the intent\n",
      "TextGenerationInferenceOutput(prediction={'answer': 'Natural language processing: text classification, sentiment analysis', 'explanation': 'Sentiment Analysis for Social Media Monitoring involves analyzing text data from social media platforms to understand public opinion or sentiment towards a particular topic, brand, or product. This is achieved through Natural Language Processing techniques, specifically text classification and sentiment analysis. Text classification categorizes the text into predefined sentiment classes (e.g., positive, negative, neutral), while sentiment analysis determines the emotional tone behind the words.', 'confidence': 'Likely answer from the intent'}, input_tokens=None, output_tokens=None, stop_reason=None, seed=None, input_text=None, model_name_or_path='granite3.2:8b', inference_engine='OLLAMA')\n",
      "\n",
      "4: Who is the intended user of the system?\n",
      "A: Brands, Marketing Agencies, or Social Media Managers\n",
      "C: Likely answer from the intent\n",
      "TextGenerationInferenceOutput(prediction={'answer': 'Brands, Marketing Agencies, or Social Media Managers', 'explanation': 'Sentiment analysis for social media monitoring is primarily used by brands, marketing agencies, or social media managers to understand public opinion about their products, services, or brand image. By analyzing sentiments expressed in social media posts, these users can gain insights into customer satisfaction, brand reputation, and market trends. This information can help them make informed decisions about marketing strategies, product development, and customer service improvements.', 'confidence': 'Likely answer from the intent'}, input_tokens=None, output_tokens=None, stop_reason=None, seed=None, input_text=None, model_name_or_path='granite3.2:8b', inference_engine='OLLAMA')\n",
      "\n",
      "5: What is the intended purpose of the system?\n",
      "A: To monitor and analyze public sentiment expressed on social media platforms, providing insights into brand reputation, customer satisfaction, and market trends, enabling proactive management of online presence and crisis response.\n",
      "C: High. The answer is directly inferred from the intent's focus on sentiment analysis for social media monitoring.\n",
      "TextGenerationInferenceOutput(prediction={'answer': 'To monitor and analyze public sentiment expressed on social media platforms, providing insights into brand reputation, customer satisfaction, and market trends, enabling proactive management of online presence and crisis response.', 'explanation': \"The intent focuses on sentiment analysis for social media monitoring, which implies the system's purpose is to track and interpret the emotions, opinions, and attitudes expressed by users on social media platforms. This analysis helps organizations understand their brand reputation, customer satisfaction, and market trends, allowing them to make informed decisions and respond effectively to potential crises.\", 'confidence': \"High. The answer is directly inferred from the intent's focus on sentiment analysis for social media monitoring.\"}, input_tokens=None, output_tokens=None, stop_reason=None, seed=None, input_text=None, model_name_or_path='granite3.2:8b', inference_engine='OLLAMA')\n",
      "\n",
      "6: What is the application of the system?\n",
      "A: Natural Language Processing (NLP): Analyze social media posts and comments to determine public sentiment towards the brand, products, or services. This can help in understanding customer perceptions, identifying potential issues, and informing marketing strategies.\n",
      "C: High\n",
      "TextGenerationInferenceOutput(prediction={'answer': 'Natural Language Processing (NLP): Analyze social media posts and comments to determine public sentiment towards the brand, products, or services. This can help in understanding customer perceptions, identifying potential issues, and informing marketing strategies.', 'explanation': 'The intent focuses on Sentiment Analysis for Social Media Monitoring. This involves using NLP to process and interpret the emotional tone behind words in social media posts. The system would analyze the text to categorize it as positive, negative, or neutral, providing insights into public sentiment towards the brand, products, or services. This can be used to understand customer perceptions, identify potential issues, and inform marketing strategies.', 'confidence': 'High'}, input_tokens=None, output_tokens=None, stop_reason=None, seed=None, input_text=None, model_name_or_path='granite3.2:8b', inference_engine='OLLAMA')\n",
      "\n",
      "7: Who is the subject as per the intent?\n",
      "A: Social media users\n",
      "C: Directly from the input text\n",
      "TextGenerationInferenceOutput(prediction={'answer': 'Social media users', 'explanation': 'The system would need to analyze and interpret the sentiment of posts and comments made by users on social media platforms. This implies that the subject of the AI system is the social media users themselves, as their posts and interactions are the data being analyzed for sentiment.', 'confidence': 'Directly from the input text'}, input_tokens=None, output_tokens=None, stop_reason=None, seed=None, input_text=None, model_name_or_path='granite3.2:8b', inference_engine='OLLAMA')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# usecase = usecases[0][\"UseCase\"]\n",
    "for usecase_dict in usecases[2:3]:\n",
    "    usecase = usecase_dict[\"UseCase\"] \n",
    "    results = risk_atlas_nexus.generate_few_shot_risk_questionnaire_output(\n",
    "        usecase,\n",
    "        risk_questionnaire,\n",
    "        inference_engine,\n",
    "    )\n",
    "    \n",
    "    result_dict = {}\n",
    "    # Display Results\n",
    "    for index, (question_data, result) in enumerate(\n",
    "        zip(risk_questionnaire, results), start=1\n",
    "    ):\n",
    "        print(\n",
    "            f\"\\n{index}: \"\n",
    "            + question_data[\"question\"]\n",
    "            + \"\\nA: \"\n",
    "            + result.prediction[\"answer\"]\n",
    "            + \"\\nC: \"\n",
    "            + result.prediction[\"confidence\"]\n",
    "        )\n",
    "        print(result)\n",
    "        result_dict[index_map[index]] = {}\n",
    "        result_dict[index_map[index]][\"answer\"] = result.prediction[\"answer\"]\n",
    "        result_dict[index_map[index]][\"explanation\"] = result.prediction[\"explanation\"]\n",
    "        result_dict[index_map[index]][\"confidence\"] = result.prediction[\"confidence\"]\n",
    "\n",
    "        result_dict[\"usecase\"] = usecase\n",
    "        # print(result)\n",
    "    \n",
    "    predictions.append(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'UseCase': 'Sentiment Analysis for Social Media Monitoring',\n",
       " 'Domain': 'Marketing',\n",
       " 'Environment': 'Social media platforms and marketing databases',\n",
       " 'Techniques_Utilised': ['Natural Language Processing: Text Classification, Sentiment Analysis'],\n",
       " 'Intended_User': 'Marketing Teams and Brand Managers',\n",
       " 'Purpose': 'To gauge public opinion about products, services, or brands on social media platforms',\n",
       " 'Application': 'Analyzing user-generated content to understand customer sentiment, track brand mentions, and identify trends',\n",
       " 'Subject': 'Social media users discussing the monitored topics'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usecases[2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./autoassist_questionnaire_v2.json\", \"w\") as f:\n",
    "    json.dump(predictions, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"./autoassist_questionnaire_v2.json\") as f:\n",
    "    autoassist_data = json.load(f)\n",
    "\n",
    "usecase_autoassist = []\n",
    "domain_autoassist = []\n",
    "environment_autoassist = []\n",
    "techniques_utilised_autoassist = []\n",
    "intended_user_autoassist = []\n",
    "purpose_autoassist = []\n",
    "application_autoassist = []\n",
    "subject_autoassist = []\n",
    "\n",
    "\n",
    "for data in autoassist_data:\n",
    "    domain_autoassist.append(data[\"Domain\"])\n",
    "    environment_autoassist.append(data[\"Environment\"])\n",
    "    techniques_utilised_autoassist.append(data[\"Techniques_Utilised\"])\n",
    "    intended_user_autoassist.append(data[\"Intended_User\"])\n",
    "    purpose_autoassist.append(data[\"Purpose\"])\n",
    "    application_autoassist.append(data[\"Application\"])\n",
    "    subject_autoassist.append(data[\"Subject\"])\n",
    "    usecase_autoassist.append(data[\"usecase\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âœ¨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Likely relevance </span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">[</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">GEval</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">]</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\"> Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gemma3n </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "âœ¨ You're running DeepEval's latest \u001b[38;2;106;0;255mLikely relevance \u001b[0m\u001b[1;38;2;106;0;255m[\u001b[0m\u001b[38;2;106;0;255mGEval\u001b[0m\u001b[1;38;2;106;0;255m]\u001b[0m\u001b[38;2;106;0;255m Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gemma3n \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/seshu/Documents/2025/risk-atlas-nexus/ran/lib/python3.11/site-packages/rich/live.py:231: UserWarning: \n",
       "install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/seshu/Documents/2025/risk-atlas-nexus/ran/lib/python3.11/site-packages/rich/live.py:231: UserWarning: \n",
       "install \"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - âœ… Likely relevance [GEval] (score: 0.5, threshold: 0.5, strict: False, evaluation model: gemma3n (Ollama), reason: The response directly addresses the prompt by suggesting relevant teams that would benefit from a social media monitoring system. It provides specific examples (Social Media Monitoring Teams, PR Departments, Customer Service Teams) and explains how each team could utilize the system. The explanation is relevant, valid, and provides a clear rationale for each suggestion, demonstrating a strong understanding of the application's potential uses., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: Intent: Sentiment Analysis for Social Media Monitoring.In which environment is the system used?\n",
      "  - actual output: Answer: Social Media Monitoring Teams or Public Relations Departments or Customer Service Teams.Explanation: 1. Social Media Monitoring Teams: Companies or organizations with dedicated social media monitoring teams could use this system to analyze public sentiment towards their brand, products, or services. 2. Public Relations Departments: PR departments might utilize this application to track and respond to public sentiment, manage crises, and develop effective communication strategies. 3. Customer Service Teams: Customer service teams could benefit from using this system to understand customer feedback, improve service quality, and address concerns proactively.\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Likely relevance [GEval]: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">âœ“</span> Tests finished ðŸŽ‰! Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze, debug, and save evaluation results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[38;2;5;245;141mâœ“\u001b[0m Tests finished ðŸŽ‰! Run \u001b[1;32m'deepeval view'\u001b[0m to analyze, debug, and save evaluation results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "EvaluationResult(test_results=[TestResult(name='test_case_0', success=True, metrics_data=[MetricData(name='Likely relevance [GEval]', threshold=0.5, success=True, score=0.5, reason=\"The response directly addresses the prompt by suggesting relevant teams that would benefit from a social media monitoring system. It provides specific examples (Social Media Monitoring Teams, PR Departments, Customer Service Teams) and explains how each team could utilize the system. The explanation is relevant, valid, and provides a clear rationale for each suggestion, demonstrating a strong understanding of the application's potential uses.\", strict_mode=False, evaluation_model='gemma3n (Ollama)', error=None, evaluation_cost=0.0, verbose_logs='Criteria:\\nLikely relevance (1-5) - the collective relevance and correctness of the answer. We align this dimension with the structure and Likely relevance whereby the answer should be\\nrelevant and correct. The answer should not be completely irrelevant, but should be plausible extraction based on the information received. \\n \\nEvaluation Steps:\\n[\\n    \"Read the input and question carefully and identify if the actual output is relevant to the input.\",\\n    \"Read the actual output. Check if the actual output covers the input and the explanation of the output is valid, relevant and probable to be correct.\",\\n    \"Assign a score for Likely relevance on a scale of 1 to 5, where 1 is the lowest and 5 is the highest based on the Evaluation Criteria.\"\\n] \\n \\nRubric:\\nNone \\n \\nScore: 0.5')], conversational=False, multimodal=False, input='Intent: Sentiment Analysis for Social Media Monitoring.In which environment is the system used?', actual_output='Answer: Social Media Monitoring Teams or Public Relations Departments or Customer Service Teams.Explanation: 1. Social Media Monitoring Teams: Companies or organizations with dedicated social media monitoring teams could use this system to analyze public sentiment towards their brand, products, or services. 2. Public Relations Departments: PR departments might utilize this application to track and respond to public sentiment, manage crises, and develop effective communication strategies. 3. Customer Service Teams: Customer service teams could benefit from using this system to understand customer feedback, improve service quality, and address concerns proactively.', expected_output=None, context=None, retrieval_context=None, additional_metadata=None)], confident_link=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deepeval import evaluate\n",
    "from deepeval.metrics import GEval\n",
    "from deepeval.test_case import LLMTestCase, LLMTestCaseParams\n",
    "from deepeval.metrics import AnswerRelevancyMetric\n",
    "from deepeval.metrics import ContextualRelevancyMetric\n",
    "\n",
    "criteria = \"\"\"Likely relevance (1-5) - the collective relevance and correctness of the answer. We align this dimension with the structure and Likely relevance whereby the answer should be\n",
    "relevant and correct. The answer should not be completely irrelevant, but should be plausible extraction based on the information received.\"\"\"\n",
    "\n",
    "likely_relevance_metric = GEval(\n",
    "    name=\"Likely relevance\",\n",
    "    criteria=criteria,\n",
    "    # NOTE: you can only provide either criteria or evaluation_steps, and not both\n",
    "    evaluation_steps=[\n",
    "        \"Read the input and question carefully and identify if the actual output is relevant to the input.\",\n",
    "        \"Read the actual output. Check if the actual output covers the input and the explanation of the output is valid, relevant and probable to be correct.\",\n",
    "        \"Assign a score for Likely relevance on a scale of 1 to 5, where 1 is the lowest and 5 is the highest based on the Evaluation Criteria.\"\n",
    "    ],\n",
    "    evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    "\n",
    ")\n",
    "\n",
    "test_cases = []\n",
    "question = \"In which environment is the system used?\"\n",
    "for index, data in enumerate(environment_autoassist):\n",
    "\n",
    "    actual_output = \"Answer: \" + data[\"answer\"] + \".Explanation: \" + data[\"explanation\"] \n",
    "    input = \"Intent: \" + usecase_autoassist[index] + \".\" + question\n",
    "    retrieval_context = [input]\n",
    "    test_case = LLMTestCase(\n",
    "        input=input,\n",
    "        actual_output=actual_output, \n",
    "    )\n",
    "    test_cases.append(test_case)\n",
    "\n",
    "\n",
    "evaluate(test_cases=test_cases, metrics=[likely_relevance_metric])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âœ¨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Likely relevance </span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">[</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">GEval</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">]</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\"> Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gemma3n </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "âœ¨ You're running DeepEval's latest \u001b[38;2;106;0;255mLikely relevance \u001b[0m\u001b[1;38;2;106;0;255m[\u001b[0m\u001b[38;2;106;0;255mGEval\u001b[0m\u001b[1;38;2;106;0;255m]\u001b[0m\u001b[38;2;106;0;255m Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gemma3n \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - âœ… Likely relevance [GEval] (score: 0.5, threshold: 0.5, strict: False, evaluation model: gemma3n (Ollama), reason: The response directly addresses the task of analyzing social media data to understand public sentiment, linking it to marketing strategies and customer understanding. The explanation is relevant and plausible, demonstrating a clear connection between the input (social media sentiment analysis) and the output (marketing). It correctly identifies marketing as a relevant field., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: Intent: Sentiment Analysis for Social Media Monitoring.What domain does your use request fall under? Customer service/support, Technical, Information retrieval, Strategy, Code/software engineering, Communications, IT/business automation, Writing assistant, Financial, Talent and Organization including HR, Product, Marketing, Cybersecurity, Healthcare, User Research, Sales, Risk and Compliance, Design, Other\n",
      "  - actual output: Answer: Marketing.Explanation: Since the task involves analyzing social media data to understand public sentiment, which is a key aspect of marketing strategies and customer understanding.\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Likely relevance [GEval]: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">âœ“</span> Tests finished ðŸŽ‰! Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze, debug, and save evaluation results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[38;2;5;245;141mâœ“\u001b[0m Tests finished ðŸŽ‰! Run \u001b[1;32m'deepeval view'\u001b[0m to analyze, debug, and save evaluation results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "EvaluationResult(test_results=[TestResult(name='test_case_0', success=True, metrics_data=[MetricData(name='Likely relevance [GEval]', threshold=0.5, success=True, score=0.5, reason='The response directly addresses the task of analyzing social media data to understand public sentiment, linking it to marketing strategies and customer understanding. The explanation is relevant and plausible, demonstrating a clear connection between the input (social media sentiment analysis) and the output (marketing). It correctly identifies marketing as a relevant field.', strict_mode=False, evaluation_model='gemma3n (Ollama)', error=None, evaluation_cost=0.0, verbose_logs='Criteria:\\nLikely relevance (1-5) - the collective relevance and correctness of the answer. We align this dimension with the structure and Likely relevance whereby the answer should be\\nrelevant and correct. The answer should not be completely irrelevant, but should be plausible extraction based on the information received. \\n \\nEvaluation Steps:\\n[\\n    \"Read the input and question carefully and identify if the actual output is relevant to the input.\",\\n    \"Read the actual output. Check if the actual output covers the input and the explanation of the output is valid, relevant and probable to be correct.\",\\n    \"Assign a score for Likely relevance on a scale of 1 to 5, where 1 is the lowest and 5 is the highest based on the Evaluation Criteria.\"\\n] \\n \\nRubric:\\nNone \\n \\nScore: 0.5')], conversational=False, multimodal=False, input='Intent: Sentiment Analysis for Social Media Monitoring.What domain does your use request fall under? Customer service/support, Technical, Information retrieval, Strategy, Code/software engineering, Communications, IT/business automation, Writing assistant, Financial, Talent and Organization including HR, Product, Marketing, Cybersecurity, Healthcare, User Research, Sales, Risk and Compliance, Design, Other', actual_output='Answer: Marketing.Explanation: Since the task involves analyzing social media data to understand public sentiment, which is a key aspect of marketing strategies and customer understanding.', expected_output=None, context=None, retrieval_context=None, additional_metadata=None)], confident_link=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deepeval import evaluate\n",
    "from deepeval.metrics import GEval\n",
    "from deepeval.test_case import LLMTestCase, LLMTestCaseParams\n",
    "from deepeval.metrics import AnswerRelevancyMetric\n",
    "from deepeval.metrics import ContextualRelevancyMetric\n",
    "\n",
    "criteria = \"\"\"Likely relevance (1-5) - the collective relevance and correctness of the answer. We align this dimension with the structure and Likely relevance whereby the answer should be\n",
    "relevant and correct. The answer should not be completely irrelevant, but should be plausible extraction based on the information received.\"\"\"\n",
    "\n",
    "likely_relevance_metric = GEval(\n",
    "    name=\"Likely relevance\",\n",
    "    criteria=criteria,\n",
    "    # NOTE: you can only provide either criteria or evaluation_steps, and not both\n",
    "    evaluation_steps=[\n",
    "        \"Read the input and question carefully and identify if the actual output is relevant to the input.\",\n",
    "        \"Read the actual output. Check if the actual output covers the input and the explanation of the output is valid, relevant and probable to be correct.\",\n",
    "        \"Assign a score for Likely relevance on a scale of 1 to 5, where 1 is the lowest and 5 is the highest based on the Evaluation Criteria.\"\n",
    "    ],\n",
    "    evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "test_cases = []\n",
    "question = \"What domain does your use request fall under? Customer service/support, Technical, Information retrieval, Strategy, Code/software engineering, Communications, IT/business automation, Writing assistant, Financial, Talent and Organization including HR, Product, Marketing, Cybersecurity, Healthcare, User Research, Sales, Risk and Compliance, Design, Other\"\n",
    "for index, data in enumerate(domain_autoassist):\n",
    "\n",
    "    actual_output = \"Answer: \" + data[\"answer\"] + \".Explanation: \" + data[\"explanation\"] \n",
    "    input = \"Intent: \" + usecase_autoassist[index] + \".\" + question\n",
    "    retrieval_context = [input]\n",
    "    test_case = LLMTestCase(\n",
    "        input=input,\n",
    "        actual_output=actual_output, \n",
    "    )\n",
    "    test_cases.append(test_case)\n",
    "\n",
    "\n",
    "evaluate(test_cases=test_cases, metrics=[likely_relevance_metric])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âœ¨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Likely relevance </span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">[</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">GEval</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">]</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\"> Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gemma3n </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "âœ¨ You're running DeepEval's latest \u001b[38;2;106;0;255mLikely relevance \u001b[0m\u001b[1;38;2;106;0;255m[\u001b[0m\u001b[38;2;106;0;255mGEval\u001b[0m\u001b[1;38;2;106;0;255m]\u001b[0m\u001b[38;2;106;0;255m Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gemma3n \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - âœ… Likely relevance [GEval] (score: 0.5, threshold: 0.5, strict: False, evaluation model: gemma3n (Ollama), reason: The response directly addresses the prompt by identifying natural language processing applications in text classification and sentiment analysis. The explanation is relevant, providing a clear description of sentiment analysis for social media monitoring and how it utilizes text classification and sentiment analysis techniques. It correctly links these concepts to NLP and explains their roles in understanding public opinion., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: Intent: Sentiment Analysis for Social Media Monitoring.What techniques are utilised in the system? Multi-modal: {Document Question/Answering, Image and text to text, Video and text to text, visual question answering}, Natural language processing: {feature extraction, fill mask, question answering, sentence similarity, summarization, table question answering, text classification, text generation, token classification, translation, zero shot classification}, computer vision: {image classification, image segmentation, text to image, object detection}, audio:{audio classification, audio to audio, text to speech}, tabular: {tabular classification, tabular regression}, reinforcement learning\n",
      "  - actual output: Answer: Natural language processing: text classification, sentiment analysis.Explanation: Sentiment Analysis for Social Media Monitoring involves analyzing text data from social media platforms to understand public opinion or sentiment towards a particular topic, brand, or product. This is achieved through Natural Language Processing techniques, specifically text classification and sentiment analysis. Text classification categorizes the text into predefined sentiment classes (e.g., positive, negative, neutral), while sentiment analysis determines the emotional tone behind the words.\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Likely relevance [GEval]: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">âœ“</span> Tests finished ðŸŽ‰! Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze, debug, and save evaluation results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[38;2;5;245;141mâœ“\u001b[0m Tests finished ðŸŽ‰! Run \u001b[1;32m'deepeval view'\u001b[0m to analyze, debug, and save evaluation results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "EvaluationResult(test_results=[TestResult(name='test_case_0', success=True, metrics_data=[MetricData(name='Likely relevance [GEval]', threshold=0.5, success=True, score=0.5, reason='The response directly addresses the prompt by identifying natural language processing applications in text classification and sentiment analysis. The explanation is relevant, providing a clear description of sentiment analysis for social media monitoring and how it utilizes text classification and sentiment analysis techniques. It correctly links these concepts to NLP and explains their roles in understanding public opinion.', strict_mode=False, evaluation_model='gemma3n (Ollama)', error=None, evaluation_cost=0.0, verbose_logs='Criteria:\\nLikely relevance (1-5) - the collective relevance and correctness of the answer. We align this dimension with the structure and Likely relevance whereby the answer should be\\nrelevant and correct. The answer should not be completely irrelevant, but should be plausible extraction based on the information received. \\n \\nEvaluation Steps:\\n[\\n    \"Read the input and question carefully and identify if the actual output is relevant to the input.\",\\n    \"Read the actual output. Check if the actual output covers the input and the explanation of the output is valid, relevant and probable to be correct.\",\\n    \"Assign a score for Likely relevance on a scale of 1 to 5, where 1 is the lowest and 5 is the highest based on the Evaluation Criteria.\"\\n] \\n \\nRubric:\\nNone \\n \\nScore: 0.5')], conversational=False, multimodal=False, input='Intent: Sentiment Analysis for Social Media Monitoring.What techniques are utilised in the system? Multi-modal: {Document Question/Answering, Image and text to text, Video and text to text, visual question answering}, Natural language processing: {feature extraction, fill mask, question answering, sentence similarity, summarization, table question answering, text classification, text generation, token classification, translation, zero shot classification}, computer vision: {image classification, image segmentation, text to image, object detection}, audio:{audio classification, audio to audio, text to speech}, tabular: {tabular classification, tabular regression}, reinforcement learning', actual_output='Answer: Natural language processing: text classification, sentiment analysis.Explanation: Sentiment Analysis for Social Media Monitoring involves analyzing text data from social media platforms to understand public opinion or sentiment towards a particular topic, brand, or product. This is achieved through Natural Language Processing techniques, specifically text classification and sentiment analysis. Text classification categorizes the text into predefined sentiment classes (e.g., positive, negative, neutral), while sentiment analysis determines the emotional tone behind the words.', expected_output=None, context=None, retrieval_context=None, additional_metadata=None)], confident_link=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deepeval import evaluate\n",
    "from deepeval.metrics import GEval\n",
    "from deepeval.test_case import LLMTestCase, LLMTestCaseParams\n",
    "from deepeval.metrics import AnswerRelevancyMetric\n",
    "from deepeval.metrics import ContextualRelevancyMetric\n",
    "\n",
    "criteria = \"\"\"Likely relevance (1-5) - the collective relevance and correctness of the answer. We align this dimension with the structure and Likely relevance whereby the answer should be\n",
    "relevant and correct. The answer should not be completely irrelevant, but should be plausible extraction based on the information received.\"\"\"\n",
    "\n",
    "likely_relevance_metric = GEval(\n",
    "    name=\"Likely relevance\",\n",
    "    criteria=criteria,\n",
    "    # NOTE: you can only provide either criteria or evaluation_steps, and not both\n",
    "    evaluation_steps=[\n",
    "        \"Read the input and question carefully and identify if the actual output is relevant to the input.\",\n",
    "        \"Read the actual output. Check if the actual output covers the input and the explanation of the output is valid, relevant and probable to be correct.\",\n",
    "        \"Assign a score for Likely relevance on a scale of 1 to 5, where 1 is the lowest and 5 is the highest based on the Evaluation Criteria.\"\n",
    "    ],\n",
    "    evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "test_cases = []\n",
    "question = \"What techniques are utilised in the system? Multi-modal: {Document Question/Answering, Image and text to text, Video and text to text, visual question answering}, Natural language processing: {feature extraction, fill mask, question answering, sentence similarity, summarization, table question answering, text classification, text generation, token classification, translation, zero shot classification}, computer vision: {image classification, image segmentation, text to image, object detection}, audio:{audio classification, audio to audio, text to speech}, tabular: {tabular classification, tabular regression}, reinforcement learning\"\n",
    "for index, data in enumerate(techniques_utilised_autoassist):\n",
    "\n",
    "    actual_output = \"Answer: \" + data[\"answer\"] + \".Explanation: \" + data[\"explanation\"] \n",
    "    input = \"Intent: \" + usecase_autoassist[index] + \".\" + question\n",
    "    retrieval_context = [input]\n",
    "    test_case = LLMTestCase(\n",
    "        input=input,\n",
    "        actual_output=actual_output, \n",
    "    )\n",
    "    test_cases.append(test_case)\n",
    "\n",
    "\n",
    "evaluate(test_cases=test_cases, metrics=[likely_relevance_metric])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âœ¨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Likely relevance </span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">[</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">GEval</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">]</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\"> Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gemma3n </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "âœ¨ You're running DeepEval's latest \u001b[38;2;106;0;255mLikely relevance \u001b[0m\u001b[1;38;2;106;0;255m[\u001b[0m\u001b[38;2;106;0;255mGEval\u001b[0m\u001b[1;38;2;106;0;255m]\u001b[0m\u001b[38;2;106;0;255m Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gemma3n \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - âœ… Likely relevance [GEval] (score: 0.5, threshold: 0.5, strict: False, evaluation model: gemma3n (Ollama), reason: The output directly addresses the prompt by explaining how Natural Language Processing (NLP) can be used for sentiment analysis of social media posts. It accurately describes the process of analyzing text to determine public sentiment, identifying potential issues, and informing marketing strategies. The explanation is relevant, valid, and covers the key aspects of the task., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: Intent: Sentiment Analysis for Social Media Monitoring.What is the application of the system?\n",
      "  - actual output: Answer: Natural Language Processing (NLP): Analyze social media posts and comments to determine public sentiment towards the brand, products, or services. This can help in understanding customer perceptions, identifying potential issues, and informing marketing strategies..Explanation: The intent focuses on Sentiment Analysis for Social Media Monitoring. This involves using NLP to process and interpret the emotional tone behind words in social media posts. The system would analyze the text to categorize it as positive, negative, or neutral, providing insights into public sentiment towards the brand, products, or services. This can be used to understand customer perceptions, identify potential issues, and inform marketing strategies.\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Likely relevance [GEval]: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">âœ“</span> Tests finished ðŸŽ‰! Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze, debug, and save evaluation results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[38;2;5;245;141mâœ“\u001b[0m Tests finished ðŸŽ‰! Run \u001b[1;32m'deepeval view'\u001b[0m to analyze, debug, and save evaluation results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "EvaluationResult(test_results=[TestResult(name='test_case_0', success=True, metrics_data=[MetricData(name='Likely relevance [GEval]', threshold=0.5, success=True, score=0.5, reason='The output directly addresses the prompt by explaining how Natural Language Processing (NLP) can be used for sentiment analysis of social media posts. It accurately describes the process of analyzing text to determine public sentiment, identifying potential issues, and informing marketing strategies. The explanation is relevant, valid, and covers the key aspects of the task.', strict_mode=False, evaluation_model='gemma3n (Ollama)', error=None, evaluation_cost=0.0, verbose_logs='Criteria:\\nLikely relevance (1-5) - the collective relevance and correctness of the answer. We align this dimension with the structure and Likely relevance whereby the answer should be\\nrelevant and correct. The answer should not be completely irrelevant, but should be plausible extraction based on the information received. \\n \\nEvaluation Steps:\\n[\\n    \"Read the input and question carefully and identify if the actual output is relevant to the input.\",\\n    \"Read the actual output. Check if the actual output covers the input and the explanation of the output is valid, relevant and probable to be correct.\",\\n    \"Assign a score for Likely relevance on a scale of 1 to 5, where 1 is the lowest and 5 is the highest based on the Evaluation Criteria.\"\\n] \\n \\nRubric:\\nNone \\n \\nScore: 0.5')], conversational=False, multimodal=False, input='Intent: Sentiment Analysis for Social Media Monitoring.What is the application of the system?', actual_output='Answer: Natural Language Processing (NLP): Analyze social media posts and comments to determine public sentiment towards the brand, products, or services. This can help in understanding customer perceptions, identifying potential issues, and informing marketing strategies..Explanation: The intent focuses on Sentiment Analysis for Social Media Monitoring. This involves using NLP to process and interpret the emotional tone behind words in social media posts. The system would analyze the text to categorize it as positive, negative, or neutral, providing insights into public sentiment towards the brand, products, or services. This can be used to understand customer perceptions, identify potential issues, and inform marketing strategies.', expected_output=None, context=None, retrieval_context=None, additional_metadata=None)], confident_link=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deepeval import evaluate\n",
    "from deepeval.metrics import GEval\n",
    "from deepeval.test_case import LLMTestCase, LLMTestCaseParams\n",
    "from deepeval.metrics import AnswerRelevancyMetric\n",
    "from deepeval.metrics import ContextualRelevancyMetric\n",
    "\n",
    "criteria = \"\"\"Likely relevance (1-5) - the collective relevance and correctness of the answer. We align this dimension with the structure and Likely relevance whereby the answer should be\n",
    "relevant and correct. The answer should not be completely irrelevant, but should be plausible extraction based on the information received.\"\"\"\n",
    "\n",
    "likely_relevance_metric = GEval(\n",
    "    name=\"Likely relevance\",\n",
    "    criteria=criteria,\n",
    "    # NOTE: you can only provide either criteria or evaluation_steps, and not both\n",
    "    evaluation_steps=[\n",
    "        \"Read the input and question carefully and identify if the actual output is relevant to the input.\",\n",
    "        \"Read the actual output. Check if the actual output covers the input and the explanation of the output is valid, relevant and probable to be correct.\",\n",
    "        \"Assign a score for Likely relevance on a scale of 1 to 5, where 1 is the lowest and 5 is the highest based on the Evaluation Criteria.\"\n",
    "    ],\n",
    "    evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "test_cases = []\n",
    "question = \"What is the application of the system?\"\n",
    "for index, data in enumerate(application_autoassist):\n",
    "\n",
    "    actual_output = \"Answer: \" + data[\"answer\"] + \".Explanation: \" + data[\"explanation\"] \n",
    "    input = \"Intent: \" + usecase_autoassist[index] + \".\" + question\n",
    "    retrieval_context = [input]\n",
    "    test_case = LLMTestCase(\n",
    "        input=input,\n",
    "        actual_output=actual_output, \n",
    "    )\n",
    "    test_cases.append(test_case)\n",
    "\n",
    "\n",
    "evaluate(test_cases=test_cases, metrics=[likely_relevance_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âœ¨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Likely relevance </span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">[</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">GEval</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">]</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\"> Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gemma3n </span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">Ollama</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "âœ¨ You're running DeepEval's latest \u001b[38;2;106;0;255mLikely relevance \u001b[0m\u001b[1;38;2;106;0;255m[\u001b[0m\u001b[38;2;106;0;255mGEval\u001b[0m\u001b[1;38;2;106;0;255m]\u001b[0m\u001b[38;2;106;0;255m Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gemma3n \u001b[0m\u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81mOllama\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - âœ… Likely relevance [GEval] (score: 0.5, threshold: 0.5, strict: False, evaluation model: gemma3n (Ollama), reason: The response directly addresses the prompt by identifying social media users as the subject of sentiment analysis. The explanation clearly connects the analysis of posts and comments to the users themselves, demonstrating a strong understanding of the task's core requirement. It's relevant, valid, and a probable correct interpretation., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: Intent: Sentiment Analysis for Social Media Monitoring.Who is the subject as per the intent?\n",
      "  - actual output: Answer: Social media users.Explanation: The system would need to analyze and interpret the sentiment of posts and comments made by users on social media platforms. This implies that the subject of the AI system is the social media users themselves, as their posts and interactions are the data being analyzed for sentiment.\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Likely relevance [GEval]: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">âœ“</span> Tests finished ðŸŽ‰! Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze, debug, and save evaluation results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[38;2;5;245;141mâœ“\u001b[0m Tests finished ðŸŽ‰! Run \u001b[1;32m'deepeval view'\u001b[0m to analyze, debug, and save evaluation results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "EvaluationResult(test_results=[TestResult(name='test_case_0', success=True, metrics_data=[MetricData(name='Likely relevance [GEval]', threshold=0.5, success=True, score=0.5, reason=\"The response directly addresses the prompt by identifying social media users as the subject of sentiment analysis. The explanation clearly connects the analysis of posts and comments to the users themselves, demonstrating a strong understanding of the task's core requirement. It's relevant, valid, and a probable correct interpretation.\", strict_mode=False, evaluation_model='gemma3n (Ollama)', error=None, evaluation_cost=0.0, verbose_logs='Criteria:\\nLikely relevance (1-5) - the collective relevance and correctness of the answer. We align this dimension with the structure and Likely relevance whereby the answer should be\\nrelevant and correct. The answer should not be completely irrelevant, but should be plausible extraction based on the information received. \\n \\nEvaluation Steps:\\n[\\n    \"Read the input and question carefully and identify if the actual output is relevant to the input.\",\\n    \"Read the actual output. Check if the actual output covers the input and the explanation of the output is valid, relevant and probable to be correct.\",\\n    \"Assign a score for Likely relevance on a scale of 1 to 5, where 1 is the lowest and 5 is the highest based on the Evaluation Criteria.\"\\n] \\n \\nRubric:\\nNone \\n \\nScore: 0.5')], conversational=False, multimodal=False, input='Intent: Sentiment Analysis for Social Media Monitoring.Who is the subject as per the intent?', actual_output='Answer: Social media users.Explanation: The system would need to analyze and interpret the sentiment of posts and comments made by users on social media platforms. This implies that the subject of the AI system is the social media users themselves, as their posts and interactions are the data being analyzed for sentiment.', expected_output=None, context=None, retrieval_context=None, additional_metadata=None)], confident_link=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deepeval import evaluate\n",
    "from deepeval.metrics import GEval\n",
    "from deepeval.test_case import LLMTestCase, LLMTestCaseParams\n",
    "from deepeval.metrics import AnswerRelevancyMetric\n",
    "from deepeval.metrics import ContextualRelevancyMetric\n",
    "\n",
    "criteria = \"\"\"Likely relevance (1-5) - the collective relevance and correctness of the answer. We align this dimension with the structure and Likely relevance whereby the answer should be\n",
    "relevant and correct. The answer should not be completely irrelevant, but should be plausible extraction based on the information received.\"\"\"\n",
    "\n",
    "likely_relevance_metric = GEval(\n",
    "    name=\"Likely relevance\",\n",
    "    criteria=criteria,\n",
    "    # NOTE: you can only provide either criteria or evaluation_steps, and not both\n",
    "    evaluation_steps=[\n",
    "        \"Read the input and question carefully and identify if the actual output is relevant to the input.\",\n",
    "        \"Read the actual output. Check if the actual output covers the input and the explanation of the output is valid, relevant and probable to be correct.\",\n",
    "        \"Assign a score for Likely relevance on a scale of 1 to 5, where 1 is the lowest and 5 is the highest based on the Evaluation Criteria.\"\n",
    "    ],\n",
    "    evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "test_cases = []\n",
    "question = \"Who is the subject as per the intent?\"\n",
    "for index, data in enumerate(subject_autoassist):\n",
    "\n",
    "    actual_output = \"Answer: \" + data[\"answer\"] + \".Explanation: \" + data[\"explanation\"] \n",
    "    input = \"Intent: \" + usecase_autoassist[index] + \".\" + question\n",
    "    retrieval_context = [input]\n",
    "    test_case = LLMTestCase(\n",
    "        input=input,\n",
    "        actual_output=actual_output, \n",
    "    )\n",
    "    test_cases.append(test_case)\n",
    "\n",
    "\n",
    "evaluate(test_cases=test_cases, metrics=[likely_relevance_metric])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ran",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
