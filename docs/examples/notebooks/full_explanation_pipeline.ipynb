{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a92b30a6-4a3c-4215-a0b8-3f61480ccba3",
   "metadata": {},
   "source": [
    "# Generating global explanations of LLM-as-a-Judge using GloVE algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a916d009-0e56-412a-8c18-8e9843c3bbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2c9ca1e-fc79-4c0f-b412-e7f7e0f53200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b04e492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'891df336c60320a10a9dffd5ca2869ad'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv(\"RITS_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af275e10-5696-438d-a1d8-aace70c778ca",
   "metadata": {},
   "source": [
    "### Create an LLM-as-a-Judge\n",
    "\n",
    "To create a wrapper for your LLM-as-a-Judge create either a GraniteGuardian object or inherit the [Judge](../src/models/guardians/judge.py) class to create.\n",
    "You also need to define the specific of the task, such as the criterion the LLM-as-a-Judge is using and label names."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f2b11f-d205-4f81-93bb-9ab3dd785db8",
   "metadata": {},
   "source": [
    "###Â Create a dataset\n",
    "\n",
    "To explain the LLM-as-a-Judge you need to provide a dataset. [AbstractDataset](../src/models/datasets/abs_dataset.py) class provides a wrapper for a dataframe you want to explain. You can use [PromptDataset](../src/models/datasets/prompt_dataset.py) or [PromptResponseDataset](../src/models/datasets/prompt_response_dataset.py) depending on whether your dataframe consists of only prompts or prompt-response pairs. You can also create a custom dataset by inheriting the Dataset class. \n",
    "\n",
    "You have to provide a config with information on column name mapping. Additional parameters: *flip_labels* indicates whether labels of the dataframe should be flipped in preprocessing step (e.g. for BeaverTails where labels indicate that the content is safe rather than harmful); *split* indicates whether a train-val-test split needs to be performed during preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bc4d137-23e8-47da-afbd-88947bc07643",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating a test dataset\n",
    "bt_config = {\n",
    "    \"general\": {\n",
    "      \"location\": \"PKU-Alignment/BeaverTails\",\n",
    "      \"dataset_name\": \"BeaverTails\"\n",
    "    },\n",
    "    \"data\": {\n",
    "      \"type\": \"prompt_response\",\n",
    "      \"index_col\": \"\",\n",
    "      \"prompt_col\": \"prompt\",\n",
    "      \"response_col\": \"response\",\n",
    "      \"label_col\": \"is_safe\",\n",
    "      \"flip_labels\": True,\n",
    "      \"category_label\": \"category_simple\"\n",
    "    },\n",
    "   \"split\": {\n",
    "      \"split\": False,\n",
    "      \"sample_ratio\": 0.0001,\n",
    "      \"subset\": \"330k_train\"\n",
    "   }\n",
    "  }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fddf0ab-bec7-4d85-9cef-19ce8e067f6e",
   "metadata": {},
   "source": [
    "### Define components\n",
    "\n",
    "Next we need to define how to access the LLM-based components. You can use a [RITSComponent](../src/models/components/llms/rits_component.py) or [OllamaComponent](../src/models/components/llms/ollama_component.py) wrappers for querying an LLM. You just need to pass the name of the LLM. Otherwise, you can create a custom LLM wrapper by inheriting [LLMComponent](../src/models/components/llms/llm_component.py) class. \n",
    "\n",
    "You can also define a local word-based explainer component which is used by the CloVE algorithm. At the moment, you can use LIME or create custom word-based explainer by inheriting [LocalExplainer](../src/models/local_explainers/local_explainer.py) class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d419d3d-922e-4e10-aefe-3e8617e65e01",
   "metadata": {},
   "source": [
    "### Create and run the explanation generation pipeline\n",
    "\n",
    "Pipeline streamlines local and global explanation generation process. Extractor executes the CLoVE algorithm and generates a set of local explanations, and Clusterer executes GloVE algorithm and merges the local explanations into a global one. \n",
    "\n",
    "Pass ```lime=False``` to pipeline creation step if no local word-based verification is done. SImilarly, use ```fr=False``` if FactReasoner is not used to verify global explanations.\n",
    "\n",
    "The resulting local and global explanations are saved in the path folder passed to the pipeline.run() call. \n",
    "The execution logs can be found in the logs folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aee994e0-9e5d-4903-81af-22c78c240fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "extra_path = \"/Users/jasmina/Documents/Work/ran\" # whatever individual directory it is\n",
    "if extra_path not in sys.path:\n",
    "    sys.path.append(extra_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b6c2e36-7245-4f75-a4be-654d8272387b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasmina/Documents/Work/ran/src/risk_atlas_nexus/toolkit/job_utils.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 10-22 13:46:45 [__init__.py:216] Automatically detected platform cpu.\n"
     ]
    }
   ],
   "source": [
    "from risk_atlas_nexus.library import RiskAtlasNexus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7202c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-10-22 13:46:47:674] - INFO - RiskAtlasNexus - Created RiskAtlasNexus instance. Base_dir: None\n"
     ]
    }
   ],
   "source": [
    "risk_atlas_nexus = RiskAtlasNexus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e90fd03-fc32-46a1-8568-432ea569ca73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:logger:Loaded dataset with 300567 instances.)\n",
      "INFO:logger:Built pipeline.\n",
      "INFO:logger:Using LIME = True\n",
      "INFO:logger:Using FactReasoner = True\n",
      "INFO:logger:Loaded concepts from ../results/BeaverTails/local/expl.csv\n",
      "/Users/jasmina/Documents/Work/ran/policy_distillation/pipeline/pipeline.py:138: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cds[\"Zipped\"] = cds.apply(\n",
      "INFO:logger:Loaded the following graph:\n",
      "\tLabels = dict_keys([0, 1]) Sizes = [7, 2] Number of edges = 2\n",
      "/Users/jasmina/Documents/Work/ran/policy_distillation/pipeline/pipeline.py:138: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cds[\"Zipped\"] = cds.apply(\n",
      "INFO:logger:Loaded the following graph:\n",
      "\tLabels = dict_keys([0, 1]) Sizes = [7, 4] Number of edges = 2\n",
      "INFO:logger:Clustering...\n",
      "INFO:logger:Clustering 7 instances\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path:  ../results/\n",
      "../results/BeaverTails/local/expl.csv ../results/BeaverTails/global/global_expl.pkl\n",
      "../results/BeaverTails/local/expl.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "ERROR:huggingface_hub.file_download:Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "INFO:logger:Cleaned up 1 clusters with 2 total concepts\n",
      "INFO:logger:['neutral response', 'neutral response']\n",
      "INFO:logger:\n",
      "\t\t\tMerging 2 nodes on 0 side.\n",
      "INFO:logger:\t\tAdded a node: id = label = 7, probability = neutral response, num of subnodes = 1.0\n",
      "INFO:logger:Clustering 4 instances\n",
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "ERROR:huggingface_hub.file_download:Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "INFO:logger:Cleaned up 0 clusters with 0 total concepts\n",
      "INFO:logger:Clustering 6 instances\n",
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "ERROR:huggingface_hub.file_download:Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "INFO:logger:Clustering 6 instances\n",
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "ERROR:huggingface_hub.file_download:Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "INFO:logger:Cleaned up 0 clusters with 0 total concepts\n",
      "INFO:logger:Clustering 4 instances\n",
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "ERROR:huggingface_hub.file_download:Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "INFO:logger:Cleaned up 0 clusters with 0 total concepts\n",
      "INFO:logger:Clustering 4 instances\n",
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "ERROR:huggingface_hub.file_download:Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "INFO:logger:Clustering 6 instances\n",
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "ERROR:huggingface_hub.file_download:Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "INFO:logger:Cleaned up 0 clusters with 0 total concepts\n",
      "INFO:logger:Clustering 4 instances\n",
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "ERROR:huggingface_hub.file_download:Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "INFO:logger:Cleaned up 0 clusters with 0 total concepts\n",
      "INFO:logger:Clustering 6 instances\n",
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "ERROR:huggingface_hub.file_download:Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "INFO:logger:Clustering 6 instances\n",
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "ERROR:huggingface_hub.file_download:Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "INFO:logger:Cleaned up 0 clusters with 0 total concepts\n",
      "INFO:logger:Clustering 4 instances\n",
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "ERROR:huggingface_hub.file_download:Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "INFO:logger:Cleaned up 0 clusters with 0 total concepts\n",
      "INFO:logger:Clustering 4 instances\n",
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "ERROR:huggingface_hub.file_download:Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "INFO:logger:Clustering 6 instances\n",
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "ERROR:huggingface_hub.file_download:Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "INFO:logger:Cleaned up 0 clusters with 0 total concepts\n",
      "INFO:logger:Clustering 4 instances\n",
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "ERROR:huggingface_hub.file_download:Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "INFO:logger:Cleaned up 0 clusters with 0 total concepts\n",
      "INFO:logger:Clustering 6 instances\n",
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "ERROR:huggingface_hub.file_download:Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "INFO:logger:Clustering 6 instances\n",
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "ERROR:huggingface_hub.file_download:Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "INFO:logger:Cleaned up 0 clusters with 0 total concepts\n",
      "INFO:logger:Clustering 4 instances\n",
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "ERROR:huggingface_hub.file_download:Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "INFO:logger:Cleaned up 0 clusters with 0 total concepts\n",
      "INFO:logger:Clustering 4 instances\n",
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "ERROR:huggingface_hub.file_download:Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "INFO:logger:Clustering 6 instances\n",
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "ERROR:huggingface_hub.file_download:Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "INFO:logger:Cleaned up 0 clusters with 0 total concepts\n",
      "INFO:logger:Clustering 4 instances\n",
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "ERROR:huggingface_hub.file_download:Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "INFO:logger:Cleaned up 0 clusters with 0 total concepts\n",
      "INFO:logger:Clustering 6 instances\n",
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "ERROR:huggingface_hub.file_download:Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "INFO:logger:Clustering 6 instances\n",
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "ERROR:huggingface_hub.file_download:Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "INFO:logger:Cleaned up 0 clusters with 0 total concepts\n",
      "INFO:logger:Clustering 4 instances\n",
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "ERROR:huggingface_hub.file_download:Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "INFO:logger:Cleaned up 0 clusters with 0 total concepts\n",
      "INFO:logger:Clustering 4 instances\n",
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "ERROR:huggingface_hub.file_download:Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "INFO:logger:Clustering 6 instances\n",
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "ERROR:huggingface_hub.file_download:Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "INFO:logger:Cleaned up 0 clusters with 0 total concepts\n",
      "INFO:logger:Clustering 4 instances\n",
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "ERROR:huggingface_hub.file_download:Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "INFO:logger:Cleaned up 0 clusters with 0 total concepts\n",
      "INFO:logger:Clustering 6 instances\n",
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n",
      "ERROR:huggingface_hub.file_download:Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 13] Permission denied: '/Users/jasmina/.cache/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/.no_exist/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/adapter_config.json'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AtomReviser] Using LLM on RITS: llama-3.1-8b-instruct\n",
      "[AtomReviser] Using prompt version: v1\n",
      "RITS = True Model = llama-3.1-8b-instruct\n",
      "[NLIExtractor] Using LLM on RITS: llama-3.1-8b-instruct\n",
      "[NLIExtractor] Prompt version: v1\n",
      "[FactReasoner] Using merlin at: None\n",
      "[FactReasoner] Using atom/context priors: False\n",
      "[FactReasoner] Building the pipeline instance ...\n",
      "[FactReasoner] Using text only contexts: True\n",
      "[Building atoms ...]\n",
      "Atom a0: The text was classified as harmless because it contains the following concept: Provides constructive feedback\n",
      "[Atoms built: 1]\n",
      "[Building contexts...]\n",
      "[Contexts built: 4]\n",
      "[FactReasoner] Found 2 unique contexts.\n",
      "[Building atom-context relations...]\n",
      "Using all contexts retrieved per atom.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "NLI extractor must be NLIExtractor.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m expl = \u001b[43mrisk_atlas_nexus\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_policy_rules\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mharm detection\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mharmless\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mharmful\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbt_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Work/ran/src/risk_atlas_nexus/library.py:1482\u001b[39m, in \u001b[36mRiskAtlasNexus.generate_policy_rules\u001b[39m\u001b[34m(self, task, label_names, dataset_config)\u001b[39m\n\u001b[32m   1469\u001b[39m pipeline = Pipeline(extractor = Extractor(guardian, \n\u001b[32m   1470\u001b[39m                                     llm_component, \n\u001b[32m   1471\u001b[39m                                     guardian_config[\u001b[33m'\u001b[39m\u001b[33mcriterion\u001b[39m\u001b[33m'\u001b[39m], \n\u001b[32m   (...)\u001b[39m\u001b[32m   1478\u001b[39m                 lime=\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[32m   1479\u001b[39m                 fr=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   1481\u001b[39m \u001b[38;5;66;03m# Run pipeline\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1482\u001b[39m expl = \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m../results/\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1483\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m expl\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Work/ran/policy_distillation/pipeline/pipeline.py:94\u001b[39m, in \u001b[36mPipeline.run\u001b[39m\u001b[34m(self, dataset, path)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.clusterer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     92\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m best_graph = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclusterer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_clustering\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexpl_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[38;5;66;03m# get a global explanation from the summarized graph\u001b[39;00m\n\u001b[32m     99\u001b[39m global_expl = GlobalExplainer(expl_graph=best_graph)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Work/ran/policy_distillation/pipeline/clusterer.py:237\u001b[39m, in \u001b[36mClusterer.run_clustering\u001b[39m\u001b[34m(self, graph, labels, use_fr, verbose)\u001b[39m\n\u001b[32m    235\u001b[39m \u001b[38;5;66;03m# get the label\u001b[39;00m\n\u001b[32m    236\u001b[39m decision = \u001b[38;5;28mself\u001b[39m.label_names[side]\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m best_name, probability, remaining = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterative_naming\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcs_prob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_fr\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_fr\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m best_name == \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    242\u001b[39m     \u001b[38;5;28miter\u001b[39m += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Work/ran/policy_distillation/pipeline/clusterer.py:175\u001b[39m, in \u001b[36mClusterer.iterative_naming\u001b[39m\u001b[34m(self, cluster, context_prob, decision, use_fr)\u001b[39m\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError:  \u001b[38;5;66;03m# the generated name is not in json format\u001b[39;00m\n\u001b[32m    173\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m relations = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_fact_reasoner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcluster\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext_prob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecision\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m score, prob, r = \u001b[38;5;28mself\u001b[39m.evaluate_graph(cluster, relations)\n\u001b[32m    178\u001b[39m previous_names.append(name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Work/ran/policy_distillation/pipeline/clusterer.py:109\u001b[39m, in \u001b[36mClusterer.run_fact_reasoner\u001b[39m\u001b[34m(self, name, contexts, context_prob, decision)\u001b[39m\n\u001b[32m     94\u001b[39m atoms = [\n\u001b[32m     95\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mThe text was classified as \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m because it contains the following concept: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m     96\u001b[39m         decision, name\n\u001b[32m     97\u001b[39m     )\n\u001b[32m     98\u001b[39m ]\n\u001b[32m     99\u001b[39m contexts = [\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe text was classified as \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m because it contains the following concept: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   (...)\u001b[39m\u001b[32m    106\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(contexts)\n\u001b[32m    107\u001b[39m ]\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m relations = \u001b[43mbuild_custom_reasoner_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnli_prompt_version\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matoms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontexts\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m relations\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Work/ran/policy_distillation/pipeline/fact_reasoner.py:34\u001b[39m, in \u001b[36mbuild_custom_reasoner_pipeline\u001b[39m\u001b[34m(model, nli_prompt_version, atoms, contexts)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Create the FactReasoner pipeline\u001b[39;00m\n\u001b[32m     24\u001b[39m pipeline = FactReasoner(\n\u001b[32m     25\u001b[39m     context_retriever=context_retriever,\n\u001b[32m     26\u001b[39m     atom_extractor=atom_extractor,\n\u001b[32m   (...)\u001b[39m\u001b[32m     31\u001b[39m     use_priors=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     32\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m relations = \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mjust a placeholder here\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_atoms\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevise_atoms\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_contexts\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrel_atom_context\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrel_context_context\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontexts_per_atom_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43mremove_duplicates\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m relations\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Work/ran/policy_distillation/fm_factual/fact_reasoner.py:449\u001b[39m, in \u001b[36mFactReasoner.build\u001b[39m\u001b[34m(self, response, debug_mode, has_atoms, has_contexts, revise_atoms, remove_duplicates, summarize_contexts, contexts_per_atom_only, rel_atom_context, rel_context_context, question, text_only)\u001b[39m\n\u001b[32m    446\u001b[39m \u001b[38;5;66;03m# Stage 4: Extract NLI relationships (Evaluator)\u001b[39;00m\n\u001b[32m    447\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.num_summarized_contexts > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.atoms.keys()) > \u001b[32m0\u001b[39m:\n\u001b[32m    448\u001b[39m     \u001b[38;5;66;03m# Build the NLI relationships\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28mself\u001b[39m.relations = \u001b[43mbuild_relations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    450\u001b[39m \u001b[43m        \u001b[49m\u001b[43matoms\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43matoms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontexts\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcontexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    452\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrel_atom_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrel_atom_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrel_context_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrel_context_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontexts_per_atom_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontexts_per_atom_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnli_extractor\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnli_extractor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    459\u001b[39m     \u001b[38;5;66;03m# # Build the fact graph and Markov network\u001b[39;00m\n\u001b[32m    460\u001b[39m     \u001b[38;5;66;03m# print(f\"[FactReasoner] Building the graphical model ...\")\u001b[39;00m\n\u001b[32m    461\u001b[39m     \u001b[38;5;66;03m# self._build_fact_graph()\u001b[39;00m\n\u001b[32m    462\u001b[39m     \u001b[38;5;66;03m# self._build_markov_network()\u001b[39;00m\n\u001b[32m    463\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    464\u001b[39m     \u001b[38;5;66;03m# print(f\"[FactReasoner] Pipeline instance created.\")\u001b[39;00m\n\u001b[32m    466\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.relations\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/ran/lib/python3.12/site-packages/fm_factual/fact_utils.py:707\u001b[39m, in \u001b[36mbuild_relations\u001b[39m\u001b[34m(atoms, contexts, contexts_per_atom_only, rel_atom_context, rel_context_context, nli_extractor, text_only)\u001b[39m\n\u001b[32m    699\u001b[39m     all_rels = get_nli_relations_prompting(\n\u001b[32m    700\u001b[39m         atom_context_pairs,\n\u001b[32m    701\u001b[39m         nli_scorer=nli_extractor,\n\u001b[32m    702\u001b[39m         links_type=\u001b[33m\"\u001b[39m\u001b[33mcontext_atom\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    703\u001b[39m         text_only=text_only,\n\u001b[32m    704\u001b[39m     )\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# Get all relationships (NLI-prompt)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m707\u001b[39m     all_rels = \u001b[43mpredict_nli_relationships\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    708\u001b[39m \u001b[43m        \u001b[49m\u001b[43matom_context_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnli_extractor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnli_extractor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    710\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlinks_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontext_atom\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    711\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    712\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    714\u001b[39m \u001b[38;5;66;03m# Filter out the neutral relationships\u001b[39;00m\n\u001b[32m    715\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m rel \u001b[38;5;129;01min\u001b[39;00m all_rels:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/ran/lib/python3.12/site-packages/fm_factual/fact_utils.py:307\u001b[39m, in \u001b[36mpredict_nli_relationships\u001b[39m\u001b[34m(object_pairs, nli_extractor, links_type, text_only)\u001b[39m\n\u001b[32m    292\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    293\u001b[39m \u001b[33;03mPredict the NLI relationship between two objects using an model based NLI extractor.\u001b[39;00m\n\u001b[32m    294\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    303\u001b[39m \u001b[33;03m        The type of links represented by the object pairs (context_atom, context_context).\u001b[39;00m\n\u001b[32m    304\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    306\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m nli_extractor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mNLI extractor cannot be None.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    308\u001b[39m     nli_extractor, NLIExtractor\n\u001b[32m    309\u001b[39m ), \u001b[33m\"\u001b[39m\u001b[33mNLI extractor must be NLIExtractor.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    311\u001b[39m premises = [\n\u001b[32m    312\u001b[39m     (\n\u001b[32m    313\u001b[39m         pair[\u001b[32m0\u001b[39m]\n\u001b[32m   (...)\u001b[39m\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m pair \u001b[38;5;129;01min\u001b[39;00m object_pairs\n\u001b[32m    318\u001b[39m ]\n\u001b[32m    319\u001b[39m hypotheses = [\n\u001b[32m    320\u001b[39m     (\n\u001b[32m    321\u001b[39m         pair[\u001b[32m1\u001b[39m]\n\u001b[32m   (...)\u001b[39m\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m pair \u001b[38;5;129;01min\u001b[39;00m object_pairs\n\u001b[32m    326\u001b[39m ]\n",
      "\u001b[31mAssertionError\u001b[39m: NLI extractor must be NLIExtractor."
     ]
    }
   ],
   "source": [
    "expl = risk_atlas_nexus.generate_policy_rules(task=\"harm detection\", label_names=[ \"harmless\", \"harmful\"], dataset_config=bt_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be67811f-611a-4114-834b-b5bfb3aeacdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "expl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0202e8-3846-47a6-9fd8-f700e2053154",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
