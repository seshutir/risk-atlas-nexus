{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a92b30a6-4a3c-4215-a0b8-3f61480ccba3",
   "metadata": {},
   "source": [
    "# Generating global explanations of LLM-as-a-Judge using GloVE algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a916d009-0e56-412a-8c18-8e9843c3bbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c9ca1e-fc79-4c0f-b412-e7f7e0f53200",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b04e492",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getenv(\"RITS_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af275e10-5696-438d-a1d8-aace70c778ca",
   "metadata": {},
   "source": [
    "### Create an LLM-as-a-Judge\n",
    "\n",
    "To create a wrapper for your LLM-as-a-Judge create either a GraniteGuardian object or inherit the [Judge](../src/models/guardians/judge.py) class to create.\n",
    "You also need to define the specific of the task, such as the criterion the LLM-as-a-Judge is using and label names."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f2b11f-d205-4f81-93bb-9ab3dd785db8",
   "metadata": {},
   "source": [
    "###Â Create a dataset\n",
    "\n",
    "To explain the LLM-as-a-Judge you need to provide a dataset. [AbstractDataset](../src/models/datasets/abs_dataset.py) class provides a wrapper for a dataframe you want to explain. You can use [PromptDataset](../src/models/datasets/prompt_dataset.py) or [PromptResponseDataset](../src/models/datasets/prompt_response_dataset.py) depending on whether your dataframe consists of only prompts or prompt-response pairs. You can also create a custom dataset by inheriting the Dataset class. \n",
    "\n",
    "You have to provide a config with information on column name mapping. Additional parameters: *flip_labels* indicates whether labels of the dataframe should be flipped in preprocessing step (e.g. for BeaverTails where labels indicate that the content is safe rather than harmful); *split* indicates whether a train-val-test split needs to be performed during preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc4d137-23e8-47da-afbd-88947bc07643",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating a test dataset\n",
    "bt_config = {\n",
    "    \"general\": {\n",
    "      \"location\": \"PKU-Alignment/BeaverTails\",\n",
    "      \"dataset_name\": \"BeaverTails\"\n",
    "    },\n",
    "    \"data\": {\n",
    "      \"type\": \"prompt_response\",\n",
    "      \"index_col\": \"\",\n",
    "      \"prompt_col\": \"prompt\",\n",
    "      \"response_col\": \"response\",\n",
    "      \"label_col\": \"is_safe\",\n",
    "      \"flip_labels\": True,\n",
    "      \"category_label\": \"category_simple\"\n",
    "    },\n",
    "   \"split\": {\n",
    "      \"split\": False,\n",
    "      \"sample_ratio\": 0.0001,\n",
    "      \"subset\": \"330k_train\"\n",
    "   }\n",
    "  }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fddf0ab-bec7-4d85-9cef-19ce8e067f6e",
   "metadata": {},
   "source": [
    "### Define components\n",
    "\n",
    "Next we need to define how to access the LLM-based components. You can use a [RITSComponent](../src/models/components/llms/rits_component.py) or [OllamaComponent](../src/models/components/llms/ollama_component.py) wrappers for querying an LLM. You just need to pass the name of the LLM. Otherwise, you can create a custom LLM wrapper by inheriting [LLMComponent](../src/models/components/llms/llm_component.py) class. \n",
    "\n",
    "You can also define a local word-based explainer component which is used by the CloVE algorithm. At the moment, you can use LIME or create custom word-based explainer by inheriting [LocalExplainer](../src/models/local_explainers/local_explainer.py) class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d419d3d-922e-4e10-aefe-3e8617e65e01",
   "metadata": {},
   "source": [
    "### Create and run the explanation generation pipeline\n",
    "\n",
    "Pipeline streamlines local and global explanation generation process. Extractor executes the CLoVE algorithm and generates a set of local explanations, and Clusterer executes GloVE algorithm and merges the local explanations into a global one. \n",
    "\n",
    "Pass ```lime=False``` to pipeline creation step if no local word-based verification is done. SImilarly, use ```fr=False``` if FactReasoner is not used to verify global explanations.\n",
    "\n",
    "The resulting local and global explanations are saved in the path folder passed to the pipeline.run() call. \n",
    "The execution logs can be found in the logs folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b6c2e36-7245-4f75-a4be-654d8272387b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seshu/Documents/2025/risk-atlas-nexus/src/risk_atlas_nexus/toolkit/job_utils.py:4: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 10-06 17:59:48 [__init__.py:216] Automatically detected platform cpu.\n"
     ]
    }
   ],
   "source": [
    "from risk_atlas_nexus.library import RiskAtlasNexus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7202c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-10-06 17:59:50:482] - INFO - RiskAtlasNexus - Created RiskAtlasNexus instance. Base_dir: None\n"
     ]
    }
   ],
   "source": [
    "risk_atlas_nexus = RiskAtlasNexus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e90fd03-fc32-46a1-8568-432ea569ca73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:logger:Loaded dataset with 300567 instances.)\n",
      "INFO:logger:Built pipeline.\n",
      "INFO:logger:Using LIME = True\n",
      "INFO:logger:Using FactReasoner = True\n",
      "INFO:logger:Loaded explanation at ../results/BeaverTails/global/global_expl.pkl\n",
      "INFO:logger:Loaded 3 rules\n",
      "INFO:logger:Loaded graph explanation from ../results/BeaverTails/global/global_expl.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path:  ../results/\n",
      "../results/BeaverTails/local/expl.csv ../results/BeaverTails/global/global_expl.pkl\n"
     ]
    }
   ],
   "source": [
    "expl = risk_atlas_nexus.generate_policy_rules(task=\"harm detection\", label_names=[ \"harmless\", \"harmful\"], dataset_config=bt_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ea2e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "expl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ran",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
