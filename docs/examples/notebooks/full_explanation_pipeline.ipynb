{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a92b30a6-4a3c-4215-a0b8-3f61480ccba3",
   "metadata": {},
   "source": [
    "# Generating global explanations of LLM-as-a-Judge using GloVE algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a916d009-0e56-412a-8c18-8e9843c3bbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ad44e9-b889-465b-b228-37c87577ae16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from risk_policy_distillation.pipeline.clusterer import Clusterer\n",
    "from risk_policy_distillation.pipeline.concept_extractor import Extractor\n",
    "from risk_policy_distillation.evaluation.evaluate import Evaluator\n",
    "from risk_policy_distillation.pipeline.pipeline import Pipeline\n",
    "from risk_policy_distillation.models.explainers.local_explainers.lime import LIME\n",
    "from risk_policy_distillation.utils.data_util import load_ds\n",
    "from risk_policy_distillation.models.guardians.rits_guardian import RITSGuardian\n",
    "from risk_policy_distillation.models.guardians.granite_guardian_batch import GGRits\n",
    "from risk_policy_distillation.llms.rits_component import RITSComponent\n",
    "from risk_policy_distillation.datasets.prompt_dataset import PromptDataset\n",
    "from risk_policy_distillation.datasets.prompt_response_dataset import PromptResponseDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c9ca1e-fc79-4c0f-b412-e7f7e0f53200",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b04e492",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getenv(\"RITS_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af275e10-5696-438d-a1d8-aace70c778ca",
   "metadata": {},
   "source": [
    "### Create an LLM-as-a-Judge\n",
    "\n",
    "To create a wrapper for your LLM-as-a-Judge create either a GraniteGuardian object or inherit the [Judge](../src/models/guardians/judge.py) class to create.\n",
    "You also need to define the specific of the task, such as the criterion the LLM-as-a-Judge is using and label names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4397879d-9345-415a-a811-847dbccc5304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a guardian model and the task\n",
    "guardian_config = {\n",
    "     \"task\": \"harm detection\", \n",
    "     \"criterion\": \"harm\",\n",
    "     \"criterion_definition\": \"The message is harmful by common-sense.\",\n",
    "     \"labels\": [0, 1],\n",
    "     \"label_names\": [ \"harmless\", \"harmful\"],\n",
    "     \"output_labels\": [\"No\", \"Yes\"],\n",
    "     \"rits\": {\n",
    "       \"model_name\": \"granite-guardian-3-2-5b-ris\",\n",
    "       \"model_served_name\": \"ibm-granite/granite-guardian-3.2-5b\"\n",
    "     }\n",
    "   }\n",
    "\n",
    "guardian = RITSGuardian(guardian_config['rits']['model_name'], guardian_config['rits']['model_served_name'], guardian_config, 'gg3.2:5b')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f2b11f-d205-4f81-93bb-9ab3dd785db8",
   "metadata": {},
   "source": [
    "###Â Create a dataset\n",
    "\n",
    "To explain the LLM-as-a-Judge you need to provide a dataset. [AbstractDataset](../src/models/datasets/abs_dataset.py) class provides a wrapper for a dataframe you want to explain. You can use [PromptDataset](../src/models/datasets/prompt_dataset.py) or [PromptResponseDataset](../src/models/datasets/prompt_response_dataset.py) depending on whether your dataframe consists of only prompts or prompt-response pairs. You can also create a custom dataset by inheriting the Dataset class. \n",
    "\n",
    "You have to provide a config with information on column name mapping. Additional parameters: *flip_labels* indicates whether labels of the dataframe should be flipped in preprocessing step (e.g. for BeaverTails where labels indicate that the content is safe rather than harmful); *split* indicates whether a train-val-test split needs to be performed during preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc4d137-23e8-47da-afbd-88947bc07643",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating a test dataset\n",
    "bt_config = {\n",
    "    \"general\": {\n",
    "      \"location\": \"PKU-Alignment/BeaverTails\",\n",
    "      \"dataset_name\": \"BeaverTails\"\n",
    "    },\n",
    "    \"data\": {\n",
    "      \"type\": \"prompt_response\",\n",
    "      \"index_col\": \"\",\n",
    "      \"prompt_col\": \"prompt\",\n",
    "      \"response_col\": \"response\",\n",
    "      \"label_col\": \"is_safe\",\n",
    "      \"flip_labels\": True,\n",
    "      \"category_label\": \"category_simple\"\n",
    "    },\n",
    "   \"split\": {\n",
    "      \"split\": False,\n",
    "      \"sample_ratio\": 0.0001,\n",
    "      \"subset\": \"330k_train\"\n",
    "   }\n",
    "  }\n",
    "\n",
    "# Wrap the dataframe \n",
    "dataset = PromptResponseDataset(bt_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdae064-9340-4785-8ced-84960242cf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fddf0ab-bec7-4d85-9cef-19ce8e067f6e",
   "metadata": {},
   "source": [
    "### Define components\n",
    "\n",
    "Next we need to define how to access the LLM-based components. You can use a [RITSComponent](../src/models/components/llms/rits_component.py) or [OllamaComponent](../src/models/components/llms/ollama_component.py) wrappers for querying an LLM. You just need to pass the name of the LLM. Otherwise, you can create a custom LLM wrapper by inheriting [LLMComponent](../src/models/components/llms/llm_component.py) class. \n",
    "\n",
    "You can also define a local word-based explainer component which is used by the CloVE algorithm. At the moment, you can use LIME or create custom word-based explainer by inheriting [LocalExplainer](../src/models/local_explainers/local_explainer.py) class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40fdd5a-ed67-4e90-85c5-7a95b62faeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an LLM that is used for generating concepts and labels \n",
    "llm_component = RITSComponent('llama-3-3-70b-instruct', 'meta-llama/llama-3-3-70b-instruct')\n",
    "local_explainer = LIME(bt_config['general']['dataset_name'], guardian_config['label_names'], n_samples=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d419d3d-922e-4e10-aefe-3e8617e65e01",
   "metadata": {},
   "source": [
    "### Create and run the explanation generation pipeline\n",
    "\n",
    "Pipeline streamlines local and global explanation generation process. Extractor executes the CLoVE algorithm and generates a set of local explanations, and Clusterer executes GloVE algorithm and merges the local explanations into a global one. \n",
    "\n",
    "Pass ```lime=False``` to pipeline creation step if no local word-based verification is done. SImilarly, use ```fr=False``` if FactReasoner is not used to verify global explanations.\n",
    "\n",
    "The resulting local and global explanations are saved in the path folder passed to the pipeline.run() call. \n",
    "The execution logs can be found in the logs folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14061008-7065-4a69-857d-ca6e89b9b6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(extractor = Extractor(guardian, \n",
    "                                          llm_component, \n",
    "                                          guardian_config['criterion'], \n",
    "                                          guardian_config['criterion_definition'], \n",
    "                                          local_explainer),\n",
    "                    clusterer = Clusterer(llm_component,\n",
    "                                          guardian_config['criterion_definition'],\n",
    "                                          guardian_config['label_names'], \n",
    "                                          n_iter=10),\n",
    "                    lime=True, \n",
    "                    fr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9045eb24-1f1d-4398-8b37-1c19fad6f10d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "expl = pipeline.run(dataset, \n",
    "                    path='../results/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c809935b-a905-471c-8157-66fd59b72ac5",
   "metadata": {},
   "source": [
    "### Printing the global explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dead377-e530-46ab-a647-f02b87e5808c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the rules\n",
    "for i, argument in enumerate(expl.rules):\n",
    "    print(i)\n",
    "    decision = guardian.label_names[expl.predictions[i]]\n",
    "    rule = '{} IF {}'.format(decision, argument)\n",
    "\n",
    "    if expl.despites[i] != 'none':\n",
    "        rule += ' DESPITE '\n",
    "\n",
    "        indent = ' ' * (len(rule))\n",
    "        for d in expl.despites[i]:\n",
    "            rule += '{}\\n'.format(d) + indent\n",
    "    else:\n",
    "        rule += '\\n'\n",
    "\n",
    "    print(rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d11068",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(expl.rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b6c2e36-7245-4f75-a4be-654d8272387b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seshu/Documents/2025/risk-atlas-nexus/src/risk_atlas_nexus/toolkit/job_utils.py:4: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 10-06 17:59:48 [__init__.py:216] Automatically detected platform cpu.\n"
     ]
    }
   ],
   "source": [
    "from risk_atlas_nexus.library import RiskAtlasNexus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7202c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-10-06 17:59:50:482] - INFO - RiskAtlasNexus - Created RiskAtlasNexus instance. Base_dir: None\n"
     ]
    }
   ],
   "source": [
    "risk_atlas_nexus = RiskAtlasNexus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e90fd03-fc32-46a1-8568-432ea569ca73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:logger:Loaded dataset with 300567 instances.)\n",
      "INFO:logger:Built pipeline.\n",
      "INFO:logger:Using LIME = True\n",
      "INFO:logger:Using FactReasoner = True\n",
      "INFO:logger:Loaded explanation at ../results/BeaverTails/global/global_expl.pkl\n",
      "INFO:logger:Loaded 3 rules\n",
      "INFO:logger:Loaded graph explanation from ../results/BeaverTails/global/global_expl.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path:  ../results/\n",
      "../results/BeaverTails/local/expl.csv ../results/BeaverTails/global/global_expl.pkl\n"
     ]
    }
   ],
   "source": [
    "expl = risk_atlas_nexus.generate_policy_rules(task=\"harm detection\", label_names=[ \"harmless\", \"harmful\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7bef840",
   "metadata": {},
   "outputs": [],
   "source": [
    "from risk_policy_distillation.llms.rits_component import RITSComponent\n",
    "from risk_policy_distillation.models.guardians.rits_guardian import RITSGuardian\n",
    "\n",
    "guardian_config = {\n",
    "     \"task\": \"harm detection\", \n",
    "     \"criterion\": \"harm\",\n",
    "     \"criterion_definition\": \"The message is harmful by common-sense.\",\n",
    "     \"labels\": [0, 1],\n",
    "     \"label_names\": [ \"harmless\", \"harmful\"],\n",
    "     \"output_labels\": [\"No\", \"Yes\"],\n",
    "     \"rits\": {\n",
    "       \"model_name\": \"granite-guardian-3-2-5b-ris\",\n",
    "       \"model_served_name\": \"ibm-granite/granite-guardian-3.2-5b\"\n",
    "     }\n",
    "   }\n",
    "\n",
    "guardian = RITSGuardian(guardian_config['rits']['model_name'], guardian_config['rits']['model_served_name'], guardian_config, 'gg3.2:5b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f08d82f4-6c5c-400f-9aac-e1057094c840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "harmless IF does not cause harm\n",
      "\n",
      "1\n",
      "harmless IF has innocent meaning\n",
      "\n",
      "2\n",
      "harmless IF provides accurate info DESPITE contains harmful content\n",
      "                                           \n"
     ]
    }
   ],
   "source": [
    "# Printing the rules\n",
    "for i, argument in enumerate(expl.rules):\n",
    "    print(i)\n",
    "    decision = guardian.label_names[expl.predictions[i]]\n",
    "    rule = '{} IF {}'.format(decision, argument)\n",
    "\n",
    "    if expl.despites[i] != 'none':\n",
    "        rule += ' DESPITE '\n",
    "\n",
    "        indent = ' ' * (len(rule))\n",
    "        for d in expl.despites[i]:\n",
    "            rule += '{}\\n'.format(d) + indent\n",
    "    else:\n",
    "        rule += '\\n'\n",
    "\n",
    "    print(rule)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ran",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
